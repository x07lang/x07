use std::collections::{BTreeMap, BTreeSet};
use std::path::{Path, PathBuf};
use std::time::{SystemTime, UNIX_EPOCH};

use anyhow::{Context, Result};
use clap::{Args, ValueEnum};
use jsonschema::Draft;
use regex::Regex;
use serde::{Deserialize, Serialize};
use serde_json::Value;
use walkdir::WalkDir;
use x07_contracts::{
    X07DIAG_SCHEMA_VERSION, X07_DIAG_CATALOG_SCHEMA_VERSION, X07_DIAG_COVERAGE_SCHEMA_VERSION,
};

use crate::util;

const X07_DIAG_CATALOG_SCHEMA_BYTES: &[u8] =
    include_bytes!("../../../spec/x07-diag.catalog.schema.json");
const X07_DIAG_COVERAGE_SCHEMA_BYTES: &[u8] =
    include_bytes!("../../../spec/x07-diag.coverage.schema.json");
const X07DIAG_SCHEMA_BYTES: &[u8] = include_bytes!("../../../spec/x07diag.schema.json");

const DIAG_EXTRACTED_SCHEMA_VERSION: &str = "x07.diag.extracted@0.1.0";
const DIAG_SARIF_SCHEMA_URL: &str = "https://json.schemastore.org/sarif-2.1.0.json";

const DEFAULT_CATALOG_PATH: &str = "catalog/diagnostics.json";
const DEFAULT_DOCS_PATH: &str = "docs/toolchain/diagnostic-codes.md";
const DEFAULT_EXTRACTED_PATH: &str = "target/x07diag/extracted_codes.json";
const DEFAULT_COVERAGE_PATH: &str = "target/x07diag/coverage.json";
const DEFAULT_SOURCE_ROOTS: &[&str] = &["crates", "tools"];

#[derive(Debug, Args)]
pub struct DiagArgs {
    #[command(subcommand)]
    pub cmd: Option<DiagCommand>,
}

#[derive(clap::Subcommand, Debug)]
pub enum DiagCommand {
    /// Validate catalog JSON and emit canonical JSON / Markdown docs.
    Catalog(DiagCatalogArgs),
    /// Bootstrap `catalog/diagnostics.json` from extracted source codes.
    InitCatalog(DiagInitCatalogArgs),
    /// Explain one diagnostic code from the catalog.
    Explain(DiagExplainArgs),
    /// Check source/catalog drift and fail on missing catalog entries.
    Check(DiagCheckArgs),
    /// Compute quickfix coverage from the catalog (optional observed mode from x07diag inputs).
    Coverage(DiagCoverageArgs),
    /// Convert x07diag JSON to SARIF v2.1.0.
    Sarif(DiagSarifArgs),
}

#[derive(Debug, Clone, Copy, ValueEnum, PartialEq, Eq)]
#[clap(rename_all = "kebab_case")]
pub enum DiagCatalogFormat {
    Json,
    Md,
    Both,
}

#[derive(Debug, Args)]
pub struct DiagCatalogArgs {
    /// Catalog JSON path.
    #[arg(long, value_name = "PATH", default_value = DEFAULT_CATALOG_PATH)]
    pub catalog: PathBuf,

    /// Output format.
    #[arg(long, value_enum, default_value_t = DiagCatalogFormat::Both)]
    pub format: DiagCatalogFormat,

    /// Output path for canonical catalog JSON.
    #[arg(long, value_name = "PATH")]
    pub out_json: Option<PathBuf>,

    /// Output path for generated Markdown docs.
    #[arg(long, value_name = "PATH")]
    pub out_md: Option<PathBuf>,

    /// Check-only mode: fail if generated outputs differ from committed files.
    #[arg(long)]
    pub check: bool,
}

#[derive(Debug, Args)]
pub struct DiagInitCatalogArgs {
    /// Extracted codes JSON generated by `x07 diag check`.
    #[arg(long, value_name = "PATH", default_value = DEFAULT_EXTRACTED_PATH)]
    pub from: PathBuf,

    /// Overwrite an existing catalog file.
    #[arg(long)]
    pub overwrite: bool,
}

#[derive(Debug, Args)]
pub struct DiagExplainArgs {
    /// Diagnostic code.
    #[arg(value_name = "CODE")]
    pub code: String,

    /// Catalog JSON path.
    #[arg(long, value_name = "PATH", default_value = DEFAULT_CATALOG_PATH)]
    pub catalog: PathBuf,
}

#[derive(Debug, Args)]
pub struct DiagCheckArgs {
    /// Catalog JSON path.
    #[arg(long, value_name = "PATH", default_value = DEFAULT_CATALOG_PATH)]
    pub catalog: PathBuf,

    /// Output path for extracted source codes.
    #[arg(long, value_name = "PATH", default_value = DEFAULT_EXTRACTED_PATH)]
    pub extracted_out: PathBuf,

    /// Scan source code and compare with catalog entries.
    #[arg(
        long,
        action = clap::ArgAction::Set,
        value_name = "BOOL",
        default_value = "true"
    )]
    pub scan_source: bool,

    /// Source roots (default: crates/, tools/ when present).
    #[arg(long, value_name = "DIR")]
    pub source_root: Vec<PathBuf>,

    /// Fail when catalog contains codes that are not found in source.
    #[arg(long)]
    pub fail_on_catalog_extra: bool,
}

#[derive(Debug, Args)]
pub struct DiagCoverageArgs {
    /// Catalog JSON path.
    #[arg(long, value_name = "PATH", default_value = DEFAULT_CATALOG_PATH)]
    pub catalog: PathBuf,

    /// Optional x07diag report files for observed quickfix statistics.
    #[arg(long = "inputs", value_name = "PATH")]
    pub inputs: Vec<PathBuf>,

    /// Minimum required coverage (0..1). Command exits with code 1 when below threshold.
    #[arg(long, value_name = "FLOAT")]
    pub min_coverage: Option<f64>,

    /// Severity filter for catalog coverage (comma-separated; error,warning,info,hint).
    #[arg(long, value_name = "CSV", default_value = "error,warning")]
    pub severity: String,

    /// Number of top missing quickfix codes to print in observed mode.
    #[arg(long, value_name = "N", default_value_t = 10)]
    pub top_missing: usize,

    /// Scan source code and include source-vs-catalog diff in the report.
    #[arg(
        long,
        action = clap::ArgAction::Set,
        value_name = "BOOL",
        default_value = "true"
    )]
    pub scan_source: bool,

    /// Source roots (default: crates/, tools/ when present).
    #[arg(long, value_name = "DIR")]
    pub source_root: Vec<PathBuf>,
}

#[derive(Debug, Args)]
pub struct DiagSarifArgs {
    /// Input x07diag report JSON.
    #[arg(long = "in", value_name = "PATH")]
    pub input: PathBuf,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Serialize, Deserialize)]
#[serde(rename_all = "lowercase")]
enum CatalogSeverity {
    Error,
    Warning,
    Info,
    Hint,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Serialize, Deserialize)]
#[serde(rename_all = "lowercase")]
enum CatalogStage {
    Parse,
    Lint,
    Rewrite,
    Type,
    Lower,
    Codegen,
    Link,
    Run,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Serialize, Deserialize)]
#[serde(rename_all = "lowercase")]
enum QuickfixSupport {
    Never,
    Sometimes,
    Always,
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, PartialOrd, Ord, Serialize, Deserialize)]
#[serde(rename_all = "snake_case")]
enum QuickfixKind {
    JsonPatch,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct CatalogOrigin {
    component: String,
    stage: CatalogStage,
    default_severity: CatalogSeverity,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    since: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    deprecated_since: Option<String>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    replaced_by: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct CatalogQuickfix {
    support: QuickfixSupport,
    #[serde(default)]
    kind: Vec<QuickfixKind>,
    #[serde(default)]
    auto_apply_safe: bool,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    no_quickfix_reason: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct CatalogDocBlock {
    summary: String,
    #[serde(default)]
    details_md: String,
    #[serde(default)]
    agent_strategy_md: String,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct CatalogExample {
    title: String,
    example_message: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    example_stage: Option<CatalogStage>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    example_loc_ptr: Option<String>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct CatalogEntry {
    code: String,
    #[serde(default)]
    tags: Vec<String>,
    origins: Vec<CatalogOrigin>,
    doc: CatalogDocBlock,
    quickfix: CatalogQuickfix,
    #[serde(default)]
    examples: Vec<CatalogExample>,
    #[serde(default)]
    meta: BTreeMap<String, Value>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct CatalogDoc {
    schema_version: String,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    generated_at_unix_ms: Option<u64>,
    #[serde(default, skip_serializing_if = "Option::is_none")]
    toolchain_version: Option<String>,
    #[serde(default)]
    entries: Vec<CatalogEntry>,
    #[serde(default)]
    meta: BTreeMap<String, Value>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct ExtractedCodes {
    schema_version: String,
    generated_at_unix_ms: u64,
    #[serde(default)]
    roots: Vec<String>,
    #[serde(default)]
    codes: Vec<ExtractedCodeRow>,
}

#[derive(Debug, Clone, Serialize, Deserialize)]
struct ExtractedCodeRow {
    code: String,
    component: String,
    #[serde(default)]
    files: Vec<String>,
    occurrences: u64,
}

#[derive(Debug, Clone, Serialize)]
struct CoverageSummary {
    total_codes: u64,
    with_quickfix: u64,
    without_quickfix: u64,
    coverage: f64,
}

#[derive(Debug, Clone, Serialize)]
struct CoverageComponentRow {
    component: String,
    total_codes: u64,
    with_quickfix: u64,
    coverage: f64,
}

#[derive(Debug, Clone, Serialize)]
struct CoverageMissing {
    codes_in_source_but_not_in_catalog: Vec<String>,
    codes_in_catalog_but_not_in_source: Vec<String>,
    codes_without_quickfix: Vec<String>,
}

#[derive(Debug, Clone, Serialize)]
struct CoverageReport {
    schema_version: String,
    generated_at_unix_ms: u64,
    toolchain_version: String,
    catalog_path: String,
    #[serde(default)]
    inputs: Vec<String>,
    summary: CoverageSummary,
    by_component: Vec<CoverageComponentRow>,
    missing: CoverageMissing,
}

#[derive(Debug, Deserialize)]
struct InputDiagReport {
    schema_version: String,
    #[serde(default)]
    diagnostics: Vec<InputDiag>,
}

#[derive(Debug, Deserialize)]
struct InputDiag {
    code: String,
    severity: String,
    message: String,
    #[serde(default)]
    loc: Option<InputLocation>,
    #[serde(default)]
    quickfix: Option<Value>,
}

#[derive(Debug, Deserialize)]
#[serde(tag = "kind", rename_all = "lowercase")]
enum InputLocation {
    X07Ast {
        ptr: String,
    },
    Text {
        span: InputSpan,
        #[serde(default)]
        snippet: Option<String>,
    },
}

#[derive(Debug, Deserialize)]
struct InputSpan {
    start: InputPos,
    end: InputPos,
    #[serde(default)]
    file: Option<String>,
}

#[derive(Debug, Deserialize)]
struct InputPos {
    line: u32,
    col: u32,
}

#[derive(Default)]
struct ExtractedAccum {
    files: BTreeSet<String>,
    occurrences: u64,
}

#[derive(Default)]
struct ObservedStats {
    total: u64,
    with_quickfix: u64,
    missing_by_code: BTreeMap<String, u64>,
}

pub fn cmd_diag(
    machine: &crate::reporting::MachineArgs,
    args: DiagArgs,
) -> Result<std::process::ExitCode> {
    match args.cmd {
        Some(DiagCommand::Catalog(args)) => cmd_diag_catalog(machine, args),
        Some(DiagCommand::InitCatalog(args)) => cmd_diag_init_catalog(machine, args),
        Some(DiagCommand::Explain(args)) => cmd_diag_explain(args),
        Some(DiagCommand::Check(args)) => cmd_diag_check(args),
        Some(DiagCommand::Coverage(args)) => cmd_diag_coverage(machine, args),
        Some(DiagCommand::Sarif(args)) => cmd_diag_sarif(machine, args),
        None => anyhow::bail!("missing subcommand for `x07 diag` (try --help)"),
    }
}

fn cmd_diag_catalog(
    machine: &crate::reporting::MachineArgs,
    args: DiagCatalogArgs,
) -> Result<std::process::ExitCode> {
    let catalog_path = resolve_existing_path_like(&args.catalog);
    let mut catalog = load_catalog(&catalog_path)?;
    normalize_catalog(&mut catalog);

    let semantic_errors = validate_catalog_semantics(&catalog);
    if !semantic_errors.is_empty() {
        anyhow::bail!(
            "catalog semantic validation failed:\n{}",
            semantic_errors.join("\n")
        );
    }

    let (out_json, out_md) = resolve_catalog_outputs(&args, machine.out.as_ref())?;

    let catalog_value = serde_json::to_value(&catalog).context("serialize catalog JSON")?;
    let canonical_json =
        util::canonical_jcs_bytes(&catalog_value).context("canonicalize catalog")?;
    let markdown = render_catalog_markdown(&catalog);

    let mut check_failed = false;
    if let Some(path) = out_json {
        check_failed |= write_or_check(&path, &canonical_json, args.check)?;
        if !args.check {
            println!("wrote: {}", path.display());
        }
    }
    if let Some(path) = out_md {
        check_failed |= write_or_check(&path, markdown.as_bytes(), args.check)?;
        if !args.check {
            println!("wrote: {}", path.display());
        }
    }

    if args.check && check_failed {
        return Ok(std::process::ExitCode::from(1));
    }

    Ok(std::process::ExitCode::SUCCESS)
}

fn cmd_diag_init_catalog(
    machine: &crate::reporting::MachineArgs,
    args: DiagInitCatalogArgs,
) -> Result<std::process::ExitCode> {
    let extracted_path = resolve_existing_path_like(&args.from);
    if !extracted_path.exists() {
        anyhow::bail!(
            "extracted codes file does not exist: {}",
            extracted_path.display()
        );
    }
    let bytes = std::fs::read(&extracted_path)
        .with_context(|| format!("read extracted codes: {}", extracted_path.display()))?;
    let extracted: ExtractedCodes = serde_json::from_slice(&bytes)
        .with_context(|| format!("parse extracted codes JSON: {}", extracted_path.display()))?;
    if extracted.schema_version.trim() != DIAG_EXTRACTED_SCHEMA_VERSION {
        anyhow::bail!(
            "extracted codes schema_version mismatch: expected {} got {:?}",
            DIAG_EXTRACTED_SCHEMA_VERSION,
            extracted.schema_version
        );
    }

    let out_path = machine
        .out
        .clone()
        .unwrap_or_else(|| PathBuf::from(DEFAULT_CATALOG_PATH));
    if out_path.exists() && !args.overwrite {
        anyhow::bail!(
            "catalog already exists: {} (pass --overwrite to replace)",
            out_path.display()
        );
    }

    let mut by_code: BTreeMap<String, Vec<ExtractedCodeRow>> = BTreeMap::new();
    for row in &extracted.codes {
        by_code
            .entry(row.code.clone())
            .or_default()
            .push(row.clone());
    }

    let mut catalog = CatalogDoc {
        schema_version: X07_DIAG_CATALOG_SCHEMA_VERSION.to_string(),
        generated_at_unix_ms: Some(now_unix_ms()),
        toolchain_version: Some(env!("CARGO_PKG_VERSION").to_string()),
        entries: Vec::new(),
        meta: BTreeMap::new(),
    };
    catalog.meta.insert(
        "generated_by".to_string(),
        Value::String("x07 diag init-catalog".to_string()),
    );
    catalog.meta.insert(
        "source_extracted_codes".to_string(),
        Value::String(path_to_string(&extracted_path)),
    );

    for (code, rows) in by_code {
        catalog.entries.push(build_stub_entry(&code, &rows));
    }
    normalize_catalog(&mut catalog);

    let semantic_errors = validate_catalog_semantics(&catalog);
    if !semantic_errors.is_empty() {
        anyhow::bail!(
            "generated catalog semantic validation failed:\n{}",
            semantic_errors.join("\n")
        );
    }

    let value = serde_json::to_value(&catalog).context("serialize generated catalog")?;
    let schema_errors = validate_schema(X07_DIAG_CATALOG_SCHEMA_BYTES, &value)?;
    if !schema_errors.is_empty() {
        anyhow::bail!(
            "generated catalog schema validation failed:\n{}",
            schema_errors.join("\n")
        );
    }

    let out_bytes = util::canonical_jcs_bytes(&value).context("canonicalize generated catalog")?;
    util::write_atomic(&out_path, &out_bytes)
        .with_context(|| format!("write catalog: {}", out_path.display()))?;
    println!("wrote: {}", out_path.display());
    println!("entries: {}", catalog.entries.len());
    Ok(std::process::ExitCode::SUCCESS)
}

fn cmd_diag_explain(args: DiagExplainArgs) -> Result<std::process::ExitCode> {
    let catalog_path = resolve_existing_path_like(&args.catalog);
    let mut catalog = load_catalog(&catalog_path)?;
    normalize_catalog(&mut catalog);
    let code = args.code.trim();
    if code.is_empty() {
        anyhow::bail!("CODE must be non-empty");
    }
    let Some(entry) = catalog.entries.iter().find(|e| e.code == code) else {
        anyhow::bail!("diagnostic code not found in catalog: {code}");
    };

    println!("code: {}", entry.code);
    println!("summary: {}", entry.doc.summary);
    println!(
        "quickfix: {}",
        quickfix_support_as_str(entry.quickfix.support)
    );
    if !entry.quickfix.kind.is_empty() {
        let kinds = entry
            .quickfix
            .kind
            .iter()
            .map(|k| quickfix_kind_as_str(*k))
            .collect::<Vec<_>>()
            .join(", ");
        println!("quickfix kinds: {kinds}");
    }
    if let Some(reason) = entry.quickfix.no_quickfix_reason.as_deref() {
        if !reason.trim().is_empty() {
            println!("no quickfix reason: {}", reason.trim());
        }
    }
    println!();
    println!("origins:");
    for origin in &entry.origins {
        println!(
            "- {} stage={} severity={}",
            origin.component,
            stage_as_str(origin.stage),
            severity_as_str(origin.default_severity)
        );
    }
    println!();
    if !entry.doc.details_md.trim().is_empty() {
        println!("details:");
        println!("{}", entry.doc.details_md.trim());
        println!();
    }
    if !entry.doc.agent_strategy_md.trim().is_empty() {
        println!("agent strategy:");
        println!("{}", entry.doc.agent_strategy_md.trim());
    }
    Ok(std::process::ExitCode::SUCCESS)
}

fn cmd_diag_check(args: DiagCheckArgs) -> Result<std::process::ExitCode> {
    let mut source_codes: BTreeSet<String> = BTreeSet::new();
    if args.scan_source {
        let roots = resolve_source_roots(&args.source_root);
        let extracted = scan_source_codes(&roots)?;
        source_codes = extracted.codes.iter().map(|row| row.code.clone()).collect();
        write_json_file(&args.extracted_out, &serde_json::to_value(&extracted)?)?;
        println!("wrote: {}", args.extracted_out.display());
    }

    let catalog_path = resolve_existing_path_like(&args.catalog);
    if !catalog_path.exists() {
        eprintln!(
            "error: catalog does not exist: {} (run `x07 diag init-catalog --from {}`)",
            catalog_path.display(),
            args.extracted_out.display()
        );
        return Ok(std::process::ExitCode::from(1));
    }

    let mut catalog = load_catalog(&catalog_path)?;
    normalize_catalog(&mut catalog);

    let mut errors = validate_catalog_semantics(&catalog);
    let mut warnings: Vec<String> = Vec::new();

    if args.scan_source {
        let catalog_codes: BTreeSet<String> =
            catalog.entries.iter().map(|e| e.code.clone()).collect();

        for code in source_codes.difference(&catalog_codes) {
            errors.push(format!("source code missing in catalog: {code}"));
        }
        for code in catalog_codes.difference(&source_codes) {
            let msg = format!("catalog code not found in source scan: {code}");
            if args.fail_on_catalog_extra {
                errors.push(msg);
            } else {
                warnings.push(msg);
            }
        }
    }

    for warning in &warnings {
        eprintln!("warning: {warning}");
    }
    if !errors.is_empty() {
        for err in &errors {
            eprintln!("error: {err}");
        }
        return Ok(std::process::ExitCode::from(1));
    }

    println!("ok: diagnostic catalog check passed");
    Ok(std::process::ExitCode::SUCCESS)
}

fn cmd_diag_coverage(
    machine: &crate::reporting::MachineArgs,
    args: DiagCoverageArgs,
) -> Result<std::process::ExitCode> {
    if let Some(min) = args.min_coverage {
        if !(0.0..=1.0).contains(&min) {
            anyhow::bail!("--min-coverage must be in [0, 1], got {min}");
        }
    }

    let catalog_path = resolve_existing_path_like(&args.catalog);
    let mut catalog = load_catalog(&catalog_path)?;
    normalize_catalog(&mut catalog);

    let severity_filter = parse_severity_filter(&args.severity)?;
    let selected_entries: Vec<&CatalogEntry> = catalog
        .entries
        .iter()
        .filter(|e| entry_matches_severity(e, &severity_filter))
        .collect();

    let total_codes = selected_entries.len() as u64;
    let with_quickfix = selected_entries
        .iter()
        .filter(|e| e.quickfix.support != QuickfixSupport::Never)
        .count() as u64;
    let without_quickfix = total_codes.saturating_sub(with_quickfix);
    let coverage = ratio(with_quickfix, total_codes);

    let by_component = compute_component_coverage(&selected_entries, &severity_filter);

    let mut codes_without_quickfix: Vec<String> = selected_entries
        .iter()
        .filter(|e| e.quickfix.support == QuickfixSupport::Never)
        .map(|e| e.code.clone())
        .collect();
    codes_without_quickfix.sort();
    codes_without_quickfix.dedup();

    let mut source_missing: Vec<String> = Vec::new();
    let mut catalog_extra: Vec<String> = Vec::new();
    if args.scan_source {
        let roots = resolve_source_roots(&args.source_root);
        let extracted = scan_source_codes(&roots)?;
        let source_codes: BTreeSet<String> =
            extracted.codes.iter().map(|row| row.code.clone()).collect();
        let catalog_codes: BTreeSet<String> =
            catalog.entries.iter().map(|e| e.code.clone()).collect();
        source_missing = source_codes.difference(&catalog_codes).cloned().collect();
        catalog_extra = catalog_codes.difference(&source_codes).cloned().collect();
    }

    let report = CoverageReport {
        schema_version: X07_DIAG_COVERAGE_SCHEMA_VERSION.to_string(),
        generated_at_unix_ms: now_unix_ms(),
        toolchain_version: env!("CARGO_PKG_VERSION").to_string(),
        catalog_path: path_to_string(&catalog_path),
        inputs: args
            .inputs
            .iter()
            .map(|p| path_to_string(p.as_path()))
            .collect(),
        summary: CoverageSummary {
            total_codes,
            with_quickfix,
            without_quickfix,
            coverage,
        },
        by_component,
        missing: CoverageMissing {
            codes_in_source_but_not_in_catalog: source_missing,
            codes_in_catalog_but_not_in_source: catalog_extra,
            codes_without_quickfix,
        },
    };

    let report_value = serde_json::to_value(&report).context("serialize coverage report")?;
    let schema_errors = validate_schema(X07_DIAG_COVERAGE_SCHEMA_BYTES, &report_value)?;
    if !schema_errors.is_empty() {
        anyhow::bail!(
            "coverage report schema validation failed:\n{}",
            schema_errors.join("\n")
        );
    }
    let out_path = machine
        .out
        .clone()
        .unwrap_or_else(|| PathBuf::from(DEFAULT_COVERAGE_PATH));
    write_json_file(&out_path, &report_value)?;
    println!("wrote: {}", out_path.display());
    println!(
        "catalog coverage: {}/{} ({:.2}%)",
        with_quickfix,
        total_codes,
        coverage * 100.0
    );

    if !args.inputs.is_empty() {
        let observed = compute_observed_stats(&args.inputs)?;
        let observed_coverage = ratio(observed.with_quickfix, observed.total);
        eprintln!(
            "observed quickfix coverage: {}/{} ({:.2}%)",
            observed.with_quickfix,
            observed.total,
            observed_coverage * 100.0
        );
        if args.top_missing > 0 {
            let mut rows: Vec<(String, u64)> = observed.missing_by_code.into_iter().collect();
            rows.sort_by(|a, b| b.1.cmp(&a.1).then_with(|| a.0.cmp(&b.0)));
            for (idx, (code, freq)) in rows.into_iter().take(args.top_missing).enumerate() {
                eprintln!(
                    "observed missing quickfix #{:02}: {} ({})",
                    idx + 1,
                    code,
                    freq
                );
            }
        }
    }

    if let Some(min) = args.min_coverage {
        if coverage + f64::EPSILON < min {
            eprintln!(
                "error: coverage {:.4} is below --min-coverage {:.4}",
                coverage, min
            );
            return Ok(std::process::ExitCode::from(1));
        }
    }

    Ok(std::process::ExitCode::SUCCESS)
}

fn cmd_diag_sarif(
    machine: &crate::reporting::MachineArgs,
    args: DiagSarifArgs,
) -> Result<std::process::ExitCode> {
    let input_path = resolve_existing_path_like(&args.input);
    let report = load_x07diag_report(&input_path)?;
    let out_path = machine
        .out
        .as_ref()
        .ok_or_else(|| anyhow::anyhow!("diag sarif: missing --out <PATH>"))?
        .clone();
    if out_path.as_os_str() == "-" {
        anyhow::bail!("--out '-' is not supported");
    }

    let mut rules: BTreeMap<String, Value> = BTreeMap::new();
    let mut results: Vec<Value> = Vec::new();
    for diag in &report.diagnostics {
        rules.entry(diag.code.clone()).or_insert_with(|| {
            serde_json::json!({
                "id": diag.code,
                "name": diag.code,
                "shortDescription": { "text": format!("x07 diagnostic {}", diag.code) }
            })
        });

        let mut result = serde_json::Map::new();
        result.insert("ruleId".to_string(), Value::String(diag.code.clone()));
        result.insert(
            "level".to_string(),
            Value::String(map_sarif_level(&diag.severity).to_string()),
        );
        result.insert(
            "message".to_string(),
            serde_json::json!({ "text": diag.message }),
        );
        if let Some(loc) = &diag.loc {
            result.insert(
                "locations".to_string(),
                Value::Array(vec![location_to_sarif(loc)]),
            );
        }
        results.push(Value::Object(result));
    }

    let sarif = serde_json::json!({
        "$schema": DIAG_SARIF_SCHEMA_URL,
        "version": "2.1.0",
        "runs": [
            {
                "tool": {
                    "driver": {
                        "name": "x07",
                        "informationUri": "https://x07lang.org/",
                        "rules": rules.values().cloned().collect::<Vec<_>>()
                    }
                },
                "results": results
            }
        ]
    });
    write_json_file(&out_path, &sarif)?;
    println!("wrote: {}", out_path.display());
    Ok(std::process::ExitCode::SUCCESS)
}

fn resolve_catalog_outputs(
    args: &DiagCatalogArgs,
    generic_out: Option<&PathBuf>,
) -> Result<(Option<PathBuf>, Option<PathBuf>)> {
    match args.format {
        DiagCatalogFormat::Json => {
            if args.out_md.is_some() {
                anyhow::bail!("--out-md is not valid when --format=json");
            }
            let out = args
                .out_json
                .clone()
                .or_else(|| generic_out.cloned())
                .unwrap_or_else(|| args.catalog.clone());
            Ok((Some(out), None))
        }
        DiagCatalogFormat::Md => {
            if args.out_json.is_some() {
                anyhow::bail!("--out-json is not valid when --format=md");
            }
            let out = args
                .out_md
                .clone()
                .or_else(|| generic_out.cloned())
                .unwrap_or_else(|| PathBuf::from(DEFAULT_DOCS_PATH));
            Ok((None, Some(out)))
        }
        DiagCatalogFormat::Both => {
            if generic_out.is_some() {
                anyhow::bail!("--out is ambiguous when --format=both; use --out-json and --out-md");
            }
            let out_json = args
                .out_json
                .clone()
                .unwrap_or_else(|| args.catalog.clone());
            let out_md = args
                .out_md
                .clone()
                .unwrap_or_else(|| PathBuf::from(DEFAULT_DOCS_PATH));
            Ok((Some(out_json), Some(out_md)))
        }
    }
}

fn write_or_check(path: &Path, expected: &[u8], check_only: bool) -> Result<bool> {
    if check_only {
        let existing = match std::fs::read(path) {
            Ok(bytes) => bytes,
            Err(_) => {
                eprintln!("error: expected file is missing: {}", path.display());
                return Ok(true);
            }
        };
        if existing != expected {
            eprintln!("error: file out of date: {}", path.display());
            return Ok(true);
        }
        return Ok(false);
    }

    util::write_atomic(path, expected).with_context(|| format!("write {}", path.display()))?;
    Ok(false)
}

fn write_json_file(path: &Path, doc: &Value) -> Result<()> {
    let bytes = util::canonical_jcs_bytes(doc).context("canonicalize JSON")?;
    util::write_atomic(path, &bytes).with_context(|| format!("write {}", path.display()))
}

fn resolve_existing_path_like(path: &Path) -> PathBuf {
    let resolved = util::resolve_existing_path_upwards(path);
    if resolved.exists() {
        resolved
    } else {
        path.to_path_buf()
    }
}

fn resolve_source_roots(raw_roots: &[PathBuf]) -> Vec<PathBuf> {
    if !raw_roots.is_empty() {
        return raw_roots.to_vec();
    }
    let mut roots: Vec<PathBuf> = Vec::new();
    for rel in DEFAULT_SOURCE_ROOTS {
        let p = PathBuf::from(rel);
        if p.is_dir() {
            roots.push(p);
        }
    }
    roots
}

fn scan_source_codes(roots: &[PathBuf]) -> Result<ExtractedCodes> {
    let re_code_field = Regex::new(r#"code\s*:\s*"([A-Z][A-Z0-9_-]{0,63})""#)
        .context("compile code-field regex")?;
    let re_diag_call = Regex::new(
        r#"(?:diag_[A-Za-z0-9_]*|with_code|error_code|warning_code)\s*\(\s*"([A-Z][A-Z0-9_-]{0,63})""#,
    )
    .context("compile diagnostic-call regex")?;
    let re_x7i_literal =
        Regex::new(r#""(X7I[0-9]{4})""#).context("compile x07import-code regex")?;

    let mut files: Vec<PathBuf> = Vec::new();
    for root in roots {
        if !root.exists() {
            continue;
        }
        for entry in WalkDir::new(root).into_iter().filter_map(|e| e.ok()) {
            if !entry.file_type().is_file() {
                continue;
            }
            let p = entry.path();
            if !is_rust_src_file(p) {
                continue;
            }
            files.push(p.to_path_buf());
        }
    }
    files.sort();

    let mut by_key: BTreeMap<(String, String), ExtractedAccum> = BTreeMap::new();
    for path in files {
        let component = infer_component(&path);
        let rel_file = path_to_string(&path);
        let text = std::fs::read_to_string(&path)
            .with_context(|| format!("read source: {}", path.display()))?;
        let include_x7i_literals = rel_file.ends_with("x07import-core/src/diagnostics.rs");
        for line in text.lines() {
            let mut line_codes: BTreeSet<String> = BTreeSet::new();
            for cap in re_code_field.captures_iter(line) {
                line_codes.insert(cap[1].to_string());
            }
            for cap in re_diag_call.captures_iter(line) {
                line_codes.insert(cap[1].to_string());
            }
            if include_x7i_literals {
                for cap in re_x7i_literal.captures_iter(line) {
                    line_codes.insert(cap[1].to_string());
                }
            }

            for code in line_codes {
                let key = (code, component.clone());
                let entry = by_key.entry(key).or_default();
                entry.occurrences = entry.occurrences.saturating_add(1);
                entry.files.insert(rel_file.clone());
            }
        }
    }

    let mut codes: Vec<ExtractedCodeRow> = Vec::new();
    for ((code, component), accum) in by_key {
        codes.push(ExtractedCodeRow {
            code,
            component,
            files: accum.files.into_iter().collect(),
            occurrences: accum.occurrences,
        });
    }
    codes.sort_by(|a, b| {
        a.code
            .cmp(&b.code)
            .then_with(|| a.component.cmp(&b.component))
    });

    Ok(ExtractedCodes {
        schema_version: DIAG_EXTRACTED_SCHEMA_VERSION.to_string(),
        generated_at_unix_ms: now_unix_ms(),
        roots: roots.iter().map(|p| path_to_string(p.as_path())).collect(),
        codes,
    })
}

fn is_rust_src_file(path: &Path) -> bool {
    if path.extension().and_then(|s| s.to_str()) != Some("rs") {
        return false;
    }
    path.components()
        .any(|c| c.as_os_str().to_string_lossy().as_ref() == "src")
}

fn infer_component(path: &Path) -> String {
    let parts: Vec<String> = path
        .components()
        .map(|c| c.as_os_str().to_string_lossy().to_string())
        .collect();
    for win in parts.windows(2) {
        if win[0] == "crates" {
            return win[1].clone();
        }
        if win[0] == "tools" {
            return format!("tools/{}", win[1]);
        }
    }
    "unknown".to_string()
}

fn build_stub_entry(code: &str, rows: &[ExtractedCodeRow]) -> CatalogEntry {
    let mut origins: Vec<CatalogOrigin> = Vec::new();
    for row in rows {
        let sample_file = row.files.first().map(String::as_str);
        origins.push(CatalogOrigin {
            component: row.component.clone(),
            stage: infer_stage(code, sample_file),
            default_severity: infer_severity(code),
            since: None,
            deprecated_since: None,
            replaced_by: None,
        });
    }
    origins.sort_by(|a, b| {
        a.component
            .cmp(&b.component)
            .then_with(|| a.stage.cmp(&b.stage))
            .then_with(|| a.default_severity.cmp(&b.default_severity))
    });
    origins.dedup_by(|a, b| {
        a.component == b.component
            && a.stage == b.stage
            && a.default_severity == b.default_severity
            && a.since == b.since
            && a.deprecated_since == b.deprecated_since
            && a.replaced_by == b.replaced_by
    });

    let mut tags: Vec<String> = Vec::new();
    if let Some(prefix) = code.split(['-', '_']).next() {
        if !prefix.trim().is_empty() {
            tags.push(prefix.to_ascii_lowercase());
        }
    }

    let enrich = classify_catalog_entry(code);
    let summary = enrich.summary;
    let details_md = enrich.details_md;
    let agent_strategy_md = enrich.agent_strategy_md;
    let quickfix = CatalogQuickfix {
        support: enrich.quickfix_support,
        kind: enrich.quickfix_kind,
        auto_apply_safe: false,
        no_quickfix_reason: enrich.no_quickfix_reason,
    };

    CatalogEntry {
        code: code.to_string(),
        tags,
        origins,
        doc: CatalogDocBlock {
            summary,
            details_md,
            agent_strategy_md,
        },
        quickfix,
        examples: Vec::new(),
        meta: BTreeMap::new(),
    }
}

#[derive(Clone, Copy)]
struct BootstrapEnrichment {
    summary: &'static str,
    details_md: &'static str,
    agent_strategy_md: &'static str,
    quickfix_support: QuickfixSupport,
    quickfix_kind: &'static [QuickfixKind],
}

fn bootstrap_enrichment(code: &str) -> Option<BootstrapEnrichment> {
    match code {
        "X07-WORLD-OS-0001" => Some(BootstrapEnrichment {
            summary: "std.os imports are forbidden in solve-* worlds.",
            details_md: "The linter emits this when a solve-world program imports `std.os.*`. A JSON Patch quickfix is emitted to remove those imports from `/imports`.",
            agent_strategy_md: "- Use solve adapters (`std.fs`, `std.rr`, `std.kv`) for deterministic worlds.\n- Apply quickfix to remove `std.os.*` imports.\n- Re-run lint/build in the target world.",
            quickfix_support: QuickfixSupport::Always,
            quickfix_kind: &[QuickfixKind::JsonPatch],
        }),
        "X07-WORLD-0001" => Some(BootstrapEnrichment {
            summary: "Program imports capabilities not allowed by the selected world flags.",
            details_md: "The linter computes forbidden imports for the current world/config and emits a JSON Patch quickfix replacing `/imports` with the allowed subset.",
            agent_strategy_md: "- Review world toggles (`--enable-fs`, `--enable-rr`, `--enable-kv`) and imports.\n- Apply quickfix to drop forbidden imports.\n- Re-run lint and tests for the same world profile.",
            quickfix_support: QuickfixSupport::Always,
            quickfix_kind: &[QuickfixKind::JsonPatch],
        }),
        "X07-ARITY-FOR-0001" => Some(BootstrapEnrichment {
            summary: "`for` has invalid arity.",
            details_md: "A quickfix is emitted when extra trailing expressions are present: they are wrapped into a `begin` body so the loop keeps canonical arity.",
            agent_strategy_md: "- If quickfix is present, apply it to wrap extra body expressions.\n- Otherwise rewrite to `for <id> <iter> <init> <body>` manually.\n- Re-run lint.",
            quickfix_support: QuickfixSupport::Sometimes,
            quickfix_kind: &[QuickfixKind::JsonPatch],
        }),
        "X07-ARITY-LET-0001" => Some(BootstrapEnrichment {
            summary: "`let`/`set` has invalid arity.",
            details_md: "A quickfix is emitted when extra trailing expressions exist: the assignment is rewritten into a `begin` block preserving later expressions.",
            agent_strategy_md: "- Apply quickfix when available.\n- Otherwise rewrite to canonical `let <name> <expr>` / `set <name> <expr>`.\n- Re-run lint.",
            quickfix_support: QuickfixSupport::Sometimes,
            quickfix_kind: &[QuickfixKind::JsonPatch],
        }),
        "X07-BORROW-0001" => Some(BootstrapEnrichment {
            summary: "Borrowing view/subview from a temporary expression is invalid.",
            details_md: "Quickfix is context-dependent: when a safe insertion point exists, linter emits JSON Patch introducing a temporary `let` binding and rewriting the borrow site.",
            agent_strategy_md: "- Prefer binding owner expressions to locals before `bytes.view`/`bytes.subview`/`vec_u8.as_view`.\n- Apply quickfix when present.\n- If quickfix is absent, perform equivalent manual rewrite and re-run lint.",
            quickfix_support: QuickfixSupport::Sometimes,
            quickfix_kind: &[QuickfixKind::JsonPatch],
        }),
        "X07-MOVE-0001" => Some(BootstrapEnrichment {
            summary: "`bytes.concat` uses the same identifier on both sides (use-after-move risk).",
            details_md: "Linter emits a JSON Patch quickfix that copies one side using `view.to_bytes(bytes.view(name))` before concat.",
            agent_strategy_md: "- Apply quickfix.\n- Confirm resulting expression keeps ownership semantics.\n- Re-run lint/build.",
            quickfix_support: QuickfixSupport::Always,
            quickfix_kind: &[QuickfixKind::JsonPatch],
        }),
        "X07-MOVE-0002" => Some(BootstrapEnrichment {
            summary: "`if` condition and branch both borrow `bytes.view` from the same owner.",
            details_md: "Linter emits a JSON Patch quickfix that copies bytes for condition use (`_x07_tmp_copy`) and rewrites the condition to avoid move conflicts.",
            agent_strategy_md: "- Apply quickfix.\n- Validate condition logic still matches intent.\n- Re-run lint/build.",
            quickfix_support: QuickfixSupport::Always,
            quickfix_kind: &[QuickfixKind::JsonPatch],
        }),
        _ => None,
    }
}

struct CatalogClassification {
    summary: String,
    details_md: String,
    agent_strategy_md: String,
    quickfix_support: QuickfixSupport,
    quickfix_kind: Vec<QuickfixKind>,
    no_quickfix_reason: Option<String>,
}

fn classify_catalog_entry(code: &str) -> CatalogClassification {
    if let Some(exact) = bootstrap_enrichment(code) {
        return CatalogClassification {
            summary: exact.summary.to_string(),
            details_md: exact.details_md.to_string(),
            agent_strategy_md: exact.agent_strategy_md.to_string(),
            quickfix_support: exact.quickfix_support,
            quickfix_kind: exact.quickfix_kind.to_vec(),
            no_quickfix_reason: None,
        };
    }

    if let Some(reason) = no_quickfix_reason(code) {
        return CatalogClassification {
            summary: format!("Diagnostic code `{code}`."),
            details_md: format!(
                "This diagnostic generally requires external state changes or human intent to resolve (`{code}`)."
            ),
            agent_strategy_md: format!(
                "- Reproduce `{code}` and capture structured context.\n- Resolve the external dependency/state.\n- Re-run the command and continue repair loop."
            ),
            quickfix_support: QuickfixSupport::Never,
            quickfix_kind: Vec::new(),
            no_quickfix_reason: Some(reason.to_string()),
        };
    }

    if code.starts_with("ETEST_") {
        return CatalogClassification {
            summary: format!("Test manifest validation diagnostic `{code}`."),
            details_md: "The issue is deterministic in `tests/tests.json` or related test assets. It can usually be repaired by structured edits to manifest fields or fixture/policy paths."
                .to_string(),
            agent_strategy_md: "- Validate `tests/tests.json` fields and world requirements.\n- Apply canonical manifest edits (id/world/entry/expect/returns/paths).\n- Re-run `x07 test`."
                .to_string(),
            quickfix_support: QuickfixSupport::Sometimes,
            quickfix_kind: Vec::new(),
            no_quickfix_reason: None,
        };
    }

    if code.starts_with("ECLI_") {
        return CatalogClassification {
            summary: format!("CLI specrows tooling diagnostic `{code}`."),
            details_md: "The input spec JSON is parse/schema/semantic-invalid or compile-invalid. Repair is usually deterministic by formatting/fixing schema shape and rerunning spec commands."
                .to_string(),
            agent_strategy_md: "- Run `x07 cli spec fmt` and `x07 cli spec check`.\n- Fix schema or semantic issues in the spec document.\n- Re-run compile/check to verify."
                .to_string(),
            quickfix_support: QuickfixSupport::Sometimes,
            quickfix_kind: Vec::new(),
            no_quickfix_reason: None,
        };
    }

    if code.starts_with("E_ARCH_") || code.starts_with("W_ARCH_") {
        return CatalogClassification {
            summary: format!("Architecture contract diagnostic `{code}`."),
            details_md: "The repository contracts under `arch/` or scanned module graph violate deterministic policy. Repair is often mechanical via manifest/lock/contracts updates."
                .to_string(),
            agent_strategy_md: "- Run `x07 arch check --write-lock`.\n- Apply suggested manifest/contracts updates.\n- Re-run `x07 arch check` until green."
                .to_string(),
            quickfix_support: QuickfixSupport::Sometimes,
            quickfix_kind: Vec::new(),
            no_quickfix_reason: None,
        };
    }

    if code.starts_with("X07PKG_") {
        return CatalogClassification {
            summary: format!("Package workflow diagnostic `{code}`."),
            details_md: "The package/index/lock workflow needs deterministic command-level remediation (dependency spec, lock refresh, credentials/config, or index selection)."
                .to_string(),
            agent_strategy_md: "- Normalize dependency specs and run `x07 pkg lock`.\n- Use `x07 pkg add/remove/versions/login/publish` as needed.\n- Re-run the original package command."
                .to_string(),
            quickfix_support: QuickfixSupport::Sometimes,
            quickfix_kind: Vec::new(),
            no_quickfix_reason: None,
        };
    }

    if code.starts_with("X07INIT_") {
        return CatalogClassification {
            summary: format!("Project/package scaffold diagnostic `{code}`."),
            details_md: "Initialization constraints (existing files/layout/arguments) can usually be resolved by deterministic filesystem and argument changes."
                .to_string(),
            agent_strategy_md: "- Adjust init target path and flags.\n- Ensure required directories/files are in expected state.\n- Re-run `x07 init` command variant."
                .to_string(),
            quickfix_support: QuickfixSupport::Sometimes,
            quickfix_kind: Vec::new(),
            no_quickfix_reason: None,
        };
    }

    if code.starts_with("X07RR_") {
        return CatalogClassification {
            summary: format!("Record/replay fixture diagnostic `{code}`."),
            details_md: "RR fixture fields and constraints are deterministic; repair usually means correcting entry schema values or regenerating fixture entries."
                .to_string(),
            agent_strategy_md: "- Validate RR entry fields (key/url/kind/op/latency).\n- Regenerate or edit fixtures deterministically.\n- Re-run `x07 rr` operation."
                .to_string(),
            quickfix_support: QuickfixSupport::Sometimes,
            quickfix_kind: Vec::new(),
            no_quickfix_reason: None,
        };
    }

    if code.starts_with("X7I") {
        return CatalogClassification {
            summary: format!("x07import subset compatibility diagnostic `{code}`."),
            details_md: "The source program uses syntax/semantics outside the supported importer subset. Repair is deterministic by rewriting the source into supported constructs."
                .to_string(),
            agent_strategy_md: "- Inspect importer diagnostic phase/context.\n- Rewrite unsupported Rust/C constructs into supported subset forms.\n- Re-run x07import and tests."
                .to_string(),
            quickfix_support: QuickfixSupport::Sometimes,
            quickfix_kind: Vec::new(),
            no_quickfix_reason: None,
        };
    }

    if code == "COMPONENT_MISSING" {
        return CatalogClassification {
            summary: "Requested toolchain component is missing.".to_string(),
            details_md:
                "The installer/updater can usually remediate by installing the missing component."
                    .to_string(),
            agent_strategy_md:
                "- Run `x07up` install/update for the missing component.\n- Re-run the failed command."
                    .to_string(),
            quickfix_support: QuickfixSupport::Sometimes,
            quickfix_kind: Vec::new(),
            no_quickfix_reason: None,
        };
    }

    if code.starts_with("X07-") || code.starts_with("X07") {
        return CatalogClassification {
            summary: format!("Core lint/schema diagnostic `{code}`."),
            details_md: "The issue is in x07AST shape, world capability use, or policy/schema constraints and is typically repairable with deterministic AST/config edits."
                .to_string(),
            agent_strategy_md:
                "- Run `x07 fmt`, `x07 lint`, and `x07 fix`.\n- Apply deterministic AST/config edits.\n- Re-run compile/test."
                    .to_string(),
            quickfix_support: QuickfixSupport::Sometimes,
            quickfix_kind: Vec::new(),
            no_quickfix_reason: None,
        };
    }

    CatalogClassification {
        summary: format!("Diagnostic code `{code}`."),
        details_md: format!(
            "Fallback catalog entry for `{code}`. Investigate producer-specific remediation."
        ),
        agent_strategy_md: format!(
            "- Reproduce `{code}` with the failing command.\n- Inspect structured diagnostic fields.\n- Apply deterministic edits and re-run."
        ),
        quickfix_support: QuickfixSupport::Sometimes,
        quickfix_kind: Vec::new(),
        no_quickfix_reason: None,
    }
}

fn no_quickfix_reason(code: &str) -> Option<&'static str> {
    match code {
        "ETEST_MANIFEST_IO" => {
            Some("Requires filesystem availability and possibly creating/restoring external files.")
        }
        "X07INIT_IO" => {
            Some("Depends on host filesystem/permissions state outside AST/config patching.")
        }
        "X07PKG_DOWNLOAD_FAILED" => {
            Some("Depends on remote archive availability and network reliability.")
        }
        "X07PKG_INDEX_FETCH" => Some("Depends on remote index/network availability."),
        "X07PKG_LOGIN_FAILED" => Some("Depends on remote registry authentication response."),
        "X07PKG_PUBLISH_FAILED" => Some("Depends on remote registry/network state."),
        "X07RR_HTTP" => Some("Depends on external HTTP service behavior."),
        "X7I0901" => {
            Some("Internal importer bug; requires toolchain fix rather than source-level quickfix.")
        }
        _ => None,
    }
}

fn infer_stage(code: &str, sample_file: Option<&str>) -> CatalogStage {
    let uc = code.to_ascii_uppercase();
    if uc.contains("PARSE") || uc.contains("JSON_PARSE") {
        return CatalogStage::Parse;
    }
    if uc.contains("TYPE") {
        return CatalogStage::Type;
    }
    if uc.contains("LOWER") {
        return CatalogStage::Lower;
    }
    if uc.contains("CODEGEN") {
        return CatalogStage::Codegen;
    }
    if uc.contains("LINK") {
        return CatalogStage::Link;
    }
    if uc.contains("RUN")
        || uc.starts_with("ETEST_")
        || uc.starts_with("X07RR_")
        || uc.contains("_RR_")
    {
        return CatalogStage::Run;
    }
    if uc.contains("REWRITE") {
        return CatalogStage::Rewrite;
    }
    if uc.contains("LINT")
        || uc.contains("ARITY")
        || uc.contains("WORLD")
        || uc.contains("BORROW")
        || uc.contains("MOVE")
    {
        return CatalogStage::Lint;
    }
    if let Some(path) = sample_file {
        if path.contains("lint") {
            return CatalogStage::Lint;
        }
        if path.contains("run") || path.contains("rr") {
            return CatalogStage::Run;
        }
    }
    CatalogStage::Lint
}

fn infer_severity(code: &str) -> CatalogSeverity {
    if code.starts_with("W_") || code.starts_with("W-") || code.starts_with("W_ARCH") {
        CatalogSeverity::Warning
    } else {
        CatalogSeverity::Error
    }
}

fn validate_catalog_semantics(catalog: &CatalogDoc) -> Vec<String> {
    let mut errors: Vec<String> = Vec::new();
    if catalog.schema_version.trim() != X07_DIAG_CATALOG_SCHEMA_VERSION {
        errors.push(format!(
            "schema_version mismatch: expected {} got {:?}",
            X07_DIAG_CATALOG_SCHEMA_VERSION, catalog.schema_version
        ));
    }
    let mut seen: BTreeSet<String> = BTreeSet::new();
    for entry in &catalog.entries {
        if !seen.insert(entry.code.clone()) {
            errors.push(format!("duplicate code: {}", entry.code));
        }
        if entry.origins.is_empty() {
            errors.push(format!("{}: missing origins[]", entry.code));
        }
        if entry.doc.summary.trim().is_empty() {
            errors.push(format!("{}: doc.summary must be non-empty", entry.code));
        }
        if entry.quickfix.support == QuickfixSupport::Never
            && entry
                .quickfix
                .no_quickfix_reason
                .as_deref()
                .is_none_or(|s| s.trim().is_empty())
        {
            errors.push(format!(
                "{}: quickfix.support=never requires no_quickfix_reason",
                entry.code
            ));
        }
    }
    errors
}

fn normalize_catalog(catalog: &mut CatalogDoc) {
    catalog.entries.sort_by(|a, b| a.code.cmp(&b.code));
    for entry in &mut catalog.entries {
        entry.tags.sort();
        entry.tags.dedup();
        entry.origins.sort_by(|a, b| {
            a.component
                .cmp(&b.component)
                .then_with(|| a.stage.cmp(&b.stage))
                .then_with(|| a.default_severity.cmp(&b.default_severity))
        });
        entry.origins.dedup_by(|a, b| {
            a.component == b.component
                && a.stage == b.stage
                && a.default_severity == b.default_severity
                && a.since == b.since
                && a.deprecated_since == b.deprecated_since
                && a.replaced_by == b.replaced_by
        });
        entry.quickfix.kind.sort();
        entry.quickfix.kind.dedup();
        entry.examples.sort_by(|a, b| {
            a.title
                .cmp(&b.title)
                .then_with(|| a.example_message.cmp(&b.example_message))
        });
    }
}

fn load_catalog(path: &Path) -> Result<CatalogDoc> {
    if !path.exists() {
        anyhow::bail!("catalog does not exist: {}", path.display());
    }
    let bytes = std::fs::read(path).with_context(|| format!("read catalog: {}", path.display()))?;
    let value: Value = serde_json::from_slice(&bytes)
        .with_context(|| format!("parse JSON: {}", path.display()))?;

    let schema_errors = validate_schema(X07_DIAG_CATALOG_SCHEMA_BYTES, &value)?;
    if !schema_errors.is_empty() {
        anyhow::bail!(
            "catalog schema validation failed for {}:\n{}",
            path.display(),
            schema_errors.join("\n")
        );
    }

    let catalog: CatalogDoc = serde_json::from_value(value)
        .with_context(|| format!("parse catalog object: {}", path.display()))?;
    Ok(catalog)
}

fn validate_schema(schema_bytes: &[u8], doc: &Value) -> Result<Vec<String>> {
    let schema_json: Value = serde_json::from_slice(schema_bytes).context("parse JSON schema")?;
    let validator = jsonschema::options()
        .with_draft(Draft::Draft202012)
        .build(&schema_json)
        .context("build schema validator")?;
    let mut out: Vec<String> = Vec::new();
    for err in validator.iter_errors(doc) {
        out.push(format!(
            "{} (instance_path={}, schema_path={})",
            err,
            err.instance_path(),
            err.schema_path()
        ));
    }
    Ok(out)
}

fn render_catalog_markdown(catalog: &CatalogDoc) -> String {
    let mut out = String::new();
    out.push_str("# Diagnostic codes catalog\n\n");
    out.push_str(
        "This file is generated from `catalog/diagnostics.json` using `x07 diag catalog`.\n\n",
    );

    let total = catalog.entries.len();
    let with_quickfix = catalog
        .entries
        .iter()
        .filter(|e| e.quickfix.support != QuickfixSupport::Never)
        .count();
    let coverage = ratio(with_quickfix as u64, total as u64);
    out.push_str(&format!(
        "- total codes: {total}\n- quickfix support (`sometimes` or `always`): {with_quickfix}\n- quickfix coverage: {:.2}%\n\n",
        coverage * 100.0
    ));

    out.push_str("| Code | Origins | Quickfix | Summary |\n");
    out.push_str("| ---- | ------- | -------- | ------- |\n");
    for entry in &catalog.entries {
        let origins = entry
            .origins
            .iter()
            .map(|o| {
                format!(
                    "{} / {} / {}",
                    o.component,
                    stage_as_str(o.stage),
                    severity_as_str(o.default_severity)
                )
            })
            .collect::<Vec<_>>()
            .join("<br/>");
        let quickfix = match entry.quickfix.support {
            QuickfixSupport::Never => "never".to_string(),
            QuickfixSupport::Sometimes => "sometimes".to_string(),
            QuickfixSupport::Always => "always".to_string(),
        };
        out.push_str(&format!(
            "| `{}` | {} | {} | {} |\n",
            entry.code,
            escape_md_table(&origins),
            quickfix,
            escape_md_table(entry.doc.summary.trim())
        ));
    }

    for entry in &catalog.entries {
        out.push_str(&format!("\n## `{}`\n\n", entry.code));
        out.push_str(&format!("Summary: {}\n\n", entry.doc.summary.trim()));
        out.push_str("Origins:\n");
        for origin in &entry.origins {
            out.push_str(&format!(
                "- {} (stage: {}, severity: {})\n",
                origin.component,
                stage_as_str(origin.stage),
                severity_as_str(origin.default_severity)
            ));
        }
        out.push('\n');

        out.push_str(&format!(
            "Quickfix support: `{}`\n",
            quickfix_support_as_str(entry.quickfix.support)
        ));
        if !entry.quickfix.kind.is_empty() {
            let kinds = entry
                .quickfix
                .kind
                .iter()
                .map(|k| quickfix_kind_as_str(*k))
                .collect::<Vec<_>>()
                .join(", ");
            out.push_str(&format!("Quickfix kinds: `{}`\n", kinds));
        }
        if let Some(reason) = entry.quickfix.no_quickfix_reason.as_deref() {
            if !reason.trim().is_empty() {
                out.push_str(&format!("No quickfix reason: {}\n", reason.trim()));
            }
        }
        out.push('\n');

        if !entry.doc.details_md.trim().is_empty() {
            out.push_str("Details:\n\n");
            out.push_str(entry.doc.details_md.trim());
            out.push_str("\n\n");
        }
        if !entry.doc.agent_strategy_md.trim().is_empty() {
            out.push_str("Agent strategy:\n\n");
            out.push_str(entry.doc.agent_strategy_md.trim());
            out.push_str("\n\n");
        }
        if !entry.examples.is_empty() {
            out.push_str("Examples:\n");
            for ex in &entry.examples {
                out.push_str(&format!(
                    "- {}: {}\n",
                    ex.title.trim(),
                    ex.example_message.trim()
                ));
            }
            out.push('\n');
        }
    }
    out
}

fn escape_md_table(input: &str) -> String {
    input.replace('|', "\\|").replace('\n', "<br/>")
}

fn parse_severity_filter(raw: &str) -> Result<BTreeSet<CatalogSeverity>> {
    let mut out = BTreeSet::new();
    for part in raw.split(',') {
        let token = part.trim().to_ascii_lowercase();
        if token.is_empty() {
            continue;
        }
        let sev = match token.as_str() {
            "error" => CatalogSeverity::Error,
            "warning" => CatalogSeverity::Warning,
            "info" => CatalogSeverity::Info,
            "hint" => CatalogSeverity::Hint,
            _ => anyhow::bail!("unsupported severity in --severity: {token}"),
        };
        out.insert(sev);
    }
    if out.is_empty() {
        anyhow::bail!("--severity produced an empty filter");
    }
    Ok(out)
}

fn entry_matches_severity(entry: &CatalogEntry, filter: &BTreeSet<CatalogSeverity>) -> bool {
    entry
        .origins
        .iter()
        .any(|origin| filter.contains(&origin.default_severity))
}

fn compute_component_coverage(
    entries: &[&CatalogEntry],
    severity_filter: &BTreeSet<CatalogSeverity>,
) -> Vec<CoverageComponentRow> {
    let mut component_total: BTreeMap<String, BTreeSet<String>> = BTreeMap::new();
    let mut component_with_qf: BTreeMap<String, BTreeSet<String>> = BTreeMap::new();

    for entry in entries {
        let has_quickfix = entry.quickfix.support != QuickfixSupport::Never;
        let mut seen_components: BTreeSet<String> = BTreeSet::new();
        for origin in &entry.origins {
            if !severity_filter.contains(&origin.default_severity) {
                continue;
            }
            if !seen_components.insert(origin.component.clone()) {
                continue;
            }
            component_total
                .entry(origin.component.clone())
                .or_default()
                .insert(entry.code.clone());
            if has_quickfix {
                component_with_qf
                    .entry(origin.component.clone())
                    .or_default()
                    .insert(entry.code.clone());
            }
        }
    }

    let mut out: Vec<CoverageComponentRow> = Vec::new();
    for (component, total_set) in component_total {
        let total = total_set.len() as u64;
        let with_qf = component_with_qf
            .get(&component)
            .map_or(0_u64, |set| set.len() as u64);
        out.push(CoverageComponentRow {
            component,
            total_codes: total,
            with_quickfix: with_qf,
            coverage: ratio(with_qf, total),
        });
    }
    out.sort_by(|a, b| a.component.cmp(&b.component));
    out
}

fn compute_observed_stats(inputs: &[PathBuf]) -> Result<ObservedStats> {
    let mut out = ObservedStats::default();
    for input in inputs {
        let path = resolve_existing_path_like(input);
        let report = load_x07diag_report(&path)?;
        for diag in &report.diagnostics {
            out.total = out.total.saturating_add(1);
            if diag.quickfix.is_some() {
                out.with_quickfix = out.with_quickfix.saturating_add(1);
            } else {
                let e = out.missing_by_code.entry(diag.code.clone()).or_insert(0);
                *e = e.saturating_add(1);
            }
        }
    }
    Ok(out)
}

fn load_x07diag_report(path: &Path) -> Result<InputDiagReport> {
    let bytes =
        std::fs::read(path).with_context(|| format!("read x07diag report: {}", path.display()))?;
    let value: Value = serde_json::from_slice(&bytes)
        .with_context(|| format!("parse x07diag JSON: {}", path.display()))?;
    let schema_errors = validate_schema(X07DIAG_SCHEMA_BYTES, &value)?;
    if !schema_errors.is_empty() {
        anyhow::bail!(
            "x07diag schema validation failed for {}:\n{}",
            path.display(),
            schema_errors.join("\n")
        );
    }
    let report: InputDiagReport = serde_json::from_value(value)
        .with_context(|| format!("parse x07diag report object: {}", path.display()))?;
    if report.schema_version.trim() != X07DIAG_SCHEMA_VERSION {
        anyhow::bail!(
            "x07diag schema_version mismatch: expected {} got {:?}",
            X07DIAG_SCHEMA_VERSION,
            report.schema_version
        );
    }
    Ok(report)
}

fn location_to_sarif(loc: &InputLocation) -> Value {
    match loc {
        InputLocation::X07Ast { ptr } => serde_json::json!({
            "logicalLocations": [
                {
                    "fullyQualifiedName": ptr
                }
            ]
        }),
        InputLocation::Text { span, snippet } => {
            let file = span.file.as_deref().unwrap_or("<unknown>");
            let start_line = span.start.line.max(1);
            let start_col = span.start.col.max(1);
            let end_line = span.end.line.max(start_line);
            let end_col = if span.end.line < start_line {
                start_col
            } else {
                span.end.col.max(1)
            };
            let mut region = serde_json::Map::new();
            region.insert("startLine".to_string(), Value::from(start_line));
            region.insert("startColumn".to_string(), Value::from(start_col));
            region.insert("endLine".to_string(), Value::from(end_line));
            region.insert("endColumn".to_string(), Value::from(end_col));
            if let Some(snippet) = snippet {
                if !snippet.trim().is_empty() {
                    region.insert(
                        "snippet".to_string(),
                        serde_json::json!({ "text": snippet.trim() }),
                    );
                }
            }
            serde_json::json!({
                "physicalLocation": {
                    "artifactLocation": { "uri": file },
                    "region": region
                }
            })
        }
    }
}

fn map_sarif_level(severity: &str) -> &'static str {
    match severity.trim().to_ascii_lowercase().as_str() {
        "error" => "error",
        "warning" => "warning",
        _ => "note",
    }
}

fn severity_as_str(severity: CatalogSeverity) -> &'static str {
    match severity {
        CatalogSeverity::Error => "error",
        CatalogSeverity::Warning => "warning",
        CatalogSeverity::Info => "info",
        CatalogSeverity::Hint => "hint",
    }
}

fn stage_as_str(stage: CatalogStage) -> &'static str {
    match stage {
        CatalogStage::Parse => "parse",
        CatalogStage::Lint => "lint",
        CatalogStage::Rewrite => "rewrite",
        CatalogStage::Type => "type",
        CatalogStage::Lower => "lower",
        CatalogStage::Codegen => "codegen",
        CatalogStage::Link => "link",
        CatalogStage::Run => "run",
    }
}

fn quickfix_support_as_str(support: QuickfixSupport) -> &'static str {
    match support {
        QuickfixSupport::Never => "never",
        QuickfixSupport::Sometimes => "sometimes",
        QuickfixSupport::Always => "always",
    }
}

fn quickfix_kind_as_str(kind: QuickfixKind) -> &'static str {
    match kind {
        QuickfixKind::JsonPatch => "json_patch",
    }
}

fn ratio(numer: u64, denom: u64) -> f64 {
    if denom == 0 {
        return 0.0;
    }
    (numer as f64) / (denom as f64)
}

fn now_unix_ms() -> u64 {
    SystemTime::now()
        .duration_since(UNIX_EPOCH)
        .unwrap_or_default()
        .as_millis() as u64
}

fn path_to_string(path: &Path) -> String {
    let as_str = if let Ok(cwd) = std::env::current_dir() {
        if let Ok(rel) = path.strip_prefix(&cwd) {
            rel.to_string_lossy().to_string()
        } else {
            path.to_string_lossy().to_string()
        }
    } else {
        path.to_string_lossy().to_string()
    };
    as_str.replace('\\', "/")
}

#[cfg(test)]
mod tests {
    use super::*;

    #[test]
    fn infer_stage_prefers_parse() {
        assert_eq!(
            infer_stage("E_ARCH_MANIFEST_JSON_PARSE", None),
            CatalogStage::Parse
        );
        assert_eq!(infer_stage("ETEST_COMPILE", None), CatalogStage::Run);
        assert_eq!(infer_stage("X07-ARITY-0000", None), CatalogStage::Lint);
    }

    #[test]
    fn infer_severity_detects_warning_prefix() {
        assert_eq!(
            infer_severity("W_ARCH_CONTRACTS_LOCK_MISSING"),
            CatalogSeverity::Warning
        );
        assert_eq!(
            infer_severity("E_ARCH_LOCK_INVALID"),
            CatalogSeverity::Error
        );
    }

    #[test]
    fn markdown_render_includes_entry() {
        let catalog = CatalogDoc {
            schema_version: X07_DIAG_CATALOG_SCHEMA_VERSION.to_string(),
            generated_at_unix_ms: None,
            toolchain_version: None,
            entries: vec![CatalogEntry {
                code: "E_ARCH_LOCK_READ".to_string(),
                tags: vec!["test".to_string()],
                origins: vec![CatalogOrigin {
                    component: "x07".to_string(),
                    stage: CatalogStage::Lint,
                    default_severity: CatalogSeverity::Error,
                    since: None,
                    deprecated_since: None,
                    replaced_by: None,
                }],
                doc: CatalogDocBlock {
                    summary: "summary".to_string(),
                    details_md: "details".to_string(),
                    agent_strategy_md: "strategy".to_string(),
                },
                quickfix: CatalogQuickfix {
                    support: QuickfixSupport::Never,
                    kind: vec![],
                    auto_apply_safe: false,
                    no_quickfix_reason: Some("manual".to_string()),
                },
                examples: vec![],
                meta: BTreeMap::new(),
            }],
            meta: BTreeMap::new(),
        };
        let md = render_catalog_markdown(&catalog);
        assert!(md.contains("`E_ARCH_LOCK_READ`"));
        assert!(md.contains("summary"));
    }

    #[test]
    fn scan_extracts_codes_from_code_field() -> Result<()> {
        let tmp = std::env::temp_dir().join(format!("x07_diag_scan_test_{}", now_unix_ms()));
        std::fs::create_dir_all(tmp.join("crates/demo/src"))?;
        std::fs::write(
            tmp.join("crates/demo/src/lib.rs"),
            r#"
            fn f() {
                let d = Diagnostic { code: "X07PKG_SPEC_INVALID".to_string(), message: "m".to_string() };
                let _x = diag_parse_error("E_ARCH_LOCK_READ", "m", None);
            }
            "#,
        )?;
        let extracted = scan_source_codes(&[tmp.join("crates")])?;
        let codes: BTreeSet<String> = extracted.codes.iter().map(|r| r.code.clone()).collect();
        assert!(codes.contains("X07PKG_SPEC_INVALID"));
        std::fs::remove_dir_all(tmp)?;
        Ok(())
    }
}
